{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import tabula\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# LLM\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# RAG\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_pdf(pdf_path):\n",
    "\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    \n",
    "    # Extract text from each page\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text() + \"\\n\"\n",
    "\n",
    "\n",
    "    # Extract tables from the PDF file\n",
    "    tables = tabula.read_pdf(pdf_path, pages=\"all\", multiple_tables=True)\n",
    "    \n",
    "    # Extract images from the PDF\n",
    "    extracted_images = []\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for image_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            # Convert image to JPEG\n",
    "            img_pil = Image.open(BytesIO(image_bytes))\n",
    "            img_pil = img_pil.convert(\"RGB\")  # Ensure compatibility for JPEG\n",
    "            img_buffer = BytesIO()\n",
    "            img_pil.save(img_buffer, format=\"JPEG\")\n",
    "\n",
    "            # Encode image bytes as base64\n",
    "            encoded_image = base64.b64encode(img_buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "            # Store image in list with metadata\n",
    "            extracted_images.append({\n",
    "                \"page\": page_num + 1,\n",
    "                \"index\": image_index + 1,\n",
    "                \"format\": \"jpeg\",  # JPEG format\n",
    "                \"image_base64\": encoded_image,  # Base64-encoded image\n",
    "                \"width\": img_pil.width,\n",
    "                \"height\": img_pil.height\n",
    "            })\n",
    "\n",
    "    return {\n",
    "        'text': text,\n",
    "        'tables': tables,\n",
    "        'images': extracted_images\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_content_from_website(url):\n",
    "    # Fetch webpage content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract text (all text in the body)\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Extract tables and convert them to pandas DataFrame\n",
    "    tables = []\n",
    "    for table in soup.find_all('table'):\n",
    "        table_data = []\n",
    "        headers = [header.get_text(strip=True) for header in table.find_all('th')]\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.get_text(strip=True) for cell in cells]\n",
    "            if row_data:\n",
    "                table_data.append(row_data)\n",
    "        \n",
    "        if table_data:\n",
    "            df = pd.DataFrame(table_data, columns=headers)\n",
    "            tables.append(df)\n",
    "\n",
    "    # Extract images and encode them in base64\n",
    "    images = []\n",
    "    for img_tag in soup.find_all('img'):\n",
    "        img_url = img_tag.get('src')\n",
    "        if img_url:\n",
    "            # Handle relative image URLs by converting them to absolute URLs\n",
    "            if not img_url.startswith('http'):\n",
    "                img_url = requests.compat.urljoin(url, img_url)\n",
    "            try:\n",
    "                img_response = requests.get(img_url)\n",
    "                img = Image.open(BytesIO(img_response.content))\n",
    "                img_format = img.format  # JPEG, PNG, etc.\n",
    "                \n",
    "                # Convert image to base64\n",
    "                img_buffer = BytesIO()\n",
    "                img.save(img_buffer, format=img_format)\n",
    "                encoded_image = base64.b64encode(img_buffer.getvalue()).decode('utf-8')\n",
    "                \n",
    "                # Store image data in metadata\n",
    "                images.append({\n",
    "                    'url': img_url,\n",
    "                    'base64': encoded_image,\n",
    "                    'format': img_format,\n",
    "                    'width': img.width,\n",
    "                    'height': img.height\n",
    "                })\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return {\n",
    "        'text': text,\n",
    "        'tables': tables,\n",
    "        'images': images\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD TO RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anike\\miniconda3\\envs\\data-science\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_30132\\791373649.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "groq_api_key = \"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\"\n",
    "\n",
    "# Initialize Groq LLM (using Mixtral for best performance)\n",
    "Table_Checker = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\", max_tokens=1)\n",
    "Table_Extractor = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
    "Chat = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize ChromaDB\n",
    "vector_db = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add text to RAG\n",
    "def add_text_to_rag(text, custom_id):\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    \n",
    "    # Split the text into chunks\n",
    "    texts = text_splitter.split_text(text)\n",
    "    \n",
    "    # Create Document objects with the provided custom ID\n",
    "    documents = []\n",
    "    for text_chunk in texts:\n",
    "        doc = Document(page_content=text_chunk, metadata={'source': custom_id})\n",
    "        documents.append(doc)\n",
    "    \n",
    "    # Add documents to ChromaDB with the custom ID\n",
    "    vector_db.add_documents(documents)\n",
    "\n",
    "    '''documents = [\n",
    "        Document(page_content=\"Document content 1\", metadata={\"source\": \"pdf_123\"}),\n",
    "        Document(page_content=\"Document content 2\", metadata={\"source\": \"pdf_123\"}),\n",
    "        Document(page_content=\"Document content 3\", metadata={\"source\": \"pdf_456\"})\n",
    "    ]\n",
    "\n",
    "    # Corresponding IDs for the documents\n",
    "    ids = [\"doc_1\", \"doc_2\", \"doc_3\"]\n",
    "\n",
    "    # Add documents to ChromaDB\n",
    "    vector_db.add_documents(documents=documents, ids=ids)'''\n",
    "\n",
    "# Function to filter and extract information from tables\n",
    "def extract_info_from_table(table, custom_id):\n",
    "\n",
    "    prompt_template = ChatPromptTemplate(\n",
    "        input_variables=[\"table\"],\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"{table}\\n\\nAnalyze the above table and tell me whether it is a proper table or no. Just return 'True' or 'False' based on you decision. I want no other output.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm_chain = LLMChain(llm=Table_Checker, prompt=prompt_template)\n",
    "    extracted_text = llm_chain.run(table=table)\n",
    "\n",
    "    good_table = True if 'True' in extracted_text else False\n",
    "\n",
    "    if not good_table:\n",
    "        return\n",
    "\n",
    "    # Define a prompt template for table summarization\n",
    "    prompt_template = ChatPromptTemplate(\n",
    "        input_variables=[\"table\"],\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"{table}\\n\\nRead the above table and get each of its records in proper serialized format.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run LLM on the table data\n",
    "    llm_chain = LLMChain(llm=Table_Extractor, prompt=prompt_template)\n",
    "    extracted_text = llm_chain.run(table=table)\n",
    "\n",
    "    add_text_to_rag(extracted_text, custom_id)\n",
    "\n",
    "\n",
    "def delete_documents_by_custom_id(custom_id):\n",
    "    vector_db.delete(where={'source': {'$eq': custom_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_30132\\4115125966.py:28: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=Table_Checker, prompt=prompt_template)\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_30132\\4115125966.py:29: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  extracted_text = llm_chain.run(table=table)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = \"1706.03762v7.pdf\"\n",
    "pdf_content = extract_from_pdf(pdf_path)\n",
    "ID = 100\n",
    "\n",
    "add_text_to_rag(pdf_content['text'], ID)\n",
    "for table in pdf_content['tables']:\n",
    "    extract_info_from_table(table, ID)\n",
    "\n",
    "# Example usage\n",
    "url = 'https://builtin.com/artificial-intelligence/deepseek-r1'  # Replace with the URL of the website you want to scrape\n",
    "website_content = extract_content_from_website(url)\n",
    "ID = 200\n",
    "\n",
    "add_text_to_rag(website_content['text'], ID)\n",
    "for table in website_content['tables']:\n",
    "    extract_info_from_table(table, ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run RAG-based QA\n",
    "def ask_question(question):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=Chat, retriever=retriever)\n",
    "    response = qa_chain.run(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 0, updating n_results = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I'm not sure I understand your question. Are you asking for a mathematical formula related to attention or focus? If so, I'm afraid I don't have any specific mathematical formulas to share. Attention and focus are complex cognitive processes that are studied in psychology and neuroscience, and while there may be mathematical models used to describe certain aspects of these processes, there is no simple formula that can capture their full complexity. If you could provide more context or clarify your question, I would be happy to try and help further.\n"
     ]
    }
   ],
   "source": [
    "print(ask_question(\"write the mathematic for attention.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
